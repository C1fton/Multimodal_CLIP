# Multimodal-CLIP
ZJU Machine Learning Project--Multimodal CLIP(2025 Autumn)

è§†è§‰è¯­è¨€å¾®è°ƒ (Vision and Language Tuning)ï¼šåŸºäº CoOp çš„é«˜æ•ˆå°‘æ ·æœ¬å­¦ä¹ 

## ğŸ‘¥ 1.ä»»åŠ¡ä»‹ç»

ä»»åŠ¡çš„ä¸»è¦ç›®æ ‡æ˜¯åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸Šå¢å¼º **CLIP (Contrastive Language-Image Pre-training)** æ¨¡å‹çš„å°‘æ ·æœ¬ (Few-shot) å’Œé›¶æ ·æœ¬ (Zero-shot) èƒ½åŠ›ï¼Œå¹¶ä¸¥æ ¼éµå®ˆâ€œ**å°½å¯èƒ½å°‘çš„å‚æ•° (as few parameters as possible)**â€è¿™ä¸€çº¦æŸã€‚

æˆ‘ä»¬æ²¡æœ‰é€‰æ‹©å¾®è°ƒæ•´ä¸ªåºå¤§çš„ CLIP æ¨¡å‹ï¼Œè€Œæ˜¯é‡‡ç”¨äº† **CoOp (Context Optimization)** æ–¹æ³•ï¼Œå³æç¤ºå­¦ä¹  (Prompt Learning)ã€‚æ­¤å¤–ï¼Œä¸ºäº†è¿›ä¸€æ­¥æŒ‘æˆ˜å‚æ•°æ•ˆç‡ï¼Œæˆ‘ä»¬è¿›è¡Œäº†ä¸€é¡¹**æ¢ç´¢æ€§å®éªŒ**ï¼šé€šè¿‡å¤§å¹…å‡å°‘ä¸Šä¸‹æ–‡é•¿åº¦ (Context Length)ï¼Œåœ¨å‚æ•°é‡å‡å°‘ 75% çš„æƒ…å†µä¸‹ï¼Œä¾ç„¶å®ç°äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚

**æ•°æ®é›†è¯´æ˜ï¼š** ç”±äºè®¡ç®—èµ„æºçš„é™åˆ¶ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† **ImageNette**ï¼ˆImageNet çš„ä¸€ä¸ª 10 ç±»å­é›†ï¼‰æ¥æ¨¡æ‹Ÿå°‘æ ·æœ¬å­¦ä¹ åœºæ™¯ï¼Œå³/CoOp/data/imagenet/images

---

## ğŸ§  2.æ–¹æ³•ä¸åŸç†

### 2.1 åŸºçº¿æ–¹æ³•ï¼šCoOp
æ ‡å‡†çš„ Zero-shot CLIP ä¾èµ–äºäººå·¥è®¾è®¡çš„æç¤ºè¯ï¼ˆPromptï¼‰ï¼Œä¾‹å¦‚ *"a photo of a [CLASS]"*ã€‚
**CoOp** çš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†è¿™äº›å›ºå®šçš„è¯æ›¿æ¢ä¸º**å¯å­¦ä¹ çš„å‘é‡ (Learnable Vectors)**ï¼Œä¹Ÿå°±æ˜¯â€œè½¯æç¤º (Soft Prompts)â€ï¼ŒåŒæ—¶ä¿æŒ CLIP çš„é¢„è®­ç»ƒå‚æ•°ï¼ˆå›¾åƒç¼–ç å™¨å’Œæ–‡æœ¬ç¼–ç å™¨ï¼‰**å®Œå…¨å†»ç»“**ã€‚

* **æ¶æ„:** CLIP (ResNet-50 éª¨å¹²ç½‘ç»œ) + å¯å­¦ä¹ çš„ä¸Šä¸‹æ–‡å‘é‡ã€‚
* **æœºåˆ¶:** æç¤ºè¯è¢«å»ºæ¨¡ä¸º `[V]_1, [V]_2, ..., [V]_M, [CLASS]`ï¼Œå…¶ä¸­ `[V]` æ˜¯é€šè¿‡åå‘ä¼ æ’­ä¼˜åŒ–çš„å‘é‡ã€‚

### 2.2 æˆ‘ä»¬çš„åˆ›æ–°ç‚¹ï¼šå‚æ•°æ•ˆç‡æ¢ç´¢ (Novelty)
ä½œä¸šå¼ºè°ƒä½¿ç”¨â€œå°½å¯èƒ½å°‘çš„å‚æ•°â€ã€‚
æ ‡å‡†çš„ CoOp è®¾ç½®ä½¿ç”¨ **16** ä¸ªä¸Šä¸‹æ–‡ Token (`N_CTX=16`)ã€‚ä¸ºäº†æè‡´ä¼˜åŒ–å‚æ•°æ•ˆç‡ï¼Œæˆ‘ä»¬è¿›è¡Œäº†å¯¹æ¯”å®éªŒï¼Œå°† `N_CTX` å‡å°‘åˆ° **4**ã€‚

* **æ ‡å‡† CoOp:** `N_CTX = 16` (åŸºçº¿)
* **é«˜æ•ˆ CoOp (Our Method):** `N_CTX = 4` (ä¼˜åŒ–ç‰ˆ) -> **å¯å­¦ä¹ å‚æ•°é‡å‡å°‘äº† 75%ã€‚**

---
## ğŸ›  3. ç¯å¢ƒä¸æ•°æ®è®¾ç½® (Environment & Data)

### 3.1 ä¾èµ–åº“
æœ¬é¡¹ç›®ä¾èµ–äº `PyTorch`, `CLIP` å’Œ `Dassl`ã€‚
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n coop_env python=3.8
conda activate coop_env

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
pip install git+[https://github.com/openai/CLIP.git](https://github.com/openai/CLIP.git)
pip install git+[https://github.com/KaiyangZhou/Dassl.pytorch.git](https://github.com/KaiyangZhou/Dassl.pytorch.git)
```

### 3.2 æ•°æ®é›†å‡†å¤‡ (ImageNette)
æˆ‘ä»¬æ•´ç†äº† ImageNette æ•°æ®é›†ä»¥é€‚é…ä»£ç åº“æ‰€éœ€çš„ ImageNet æ ‡å‡†ç›®å½•ç»“æ„ï¼š

    data/
    â””â”€â”€ imagenet/
    â”œâ”€â”€ images/
    â”‚   â”œâ”€â”€ train/ # åŒ…å« 10 ä¸ªç±»åˆ«çš„æ–‡ä»¶å¤¹
    â”‚   â””â”€â”€ val/   # åŒ…å« 10 ä¸ªç±»åˆ«çš„æ–‡ä»¶å¤¹
    â””â”€â”€ classnames.txt # ç”±è‡ªå®šä¹‰è„šæœ¬ç”Ÿæˆ
æ³¨ï¼šæˆ‘ä»¬éœ€è¦ä½¿ç”¨è‡ªå®šä¹‰è„šæœ¬ fix_imagenet.py æ¥ç”Ÿæˆé€‚ç”¨äºè¯¥å­é›†çš„ classnames.txt æ˜ å°„æ–‡ä»¶ã€‚

## ğŸš€ 4.å¦‚ä½•è¿è¡Œ(How to Run)
æˆ‘ä»¬åœ¨ Zero-shot, æ ‡å‡† CoOp (1-16 shots), å’Œ é«˜æ•ˆ CoOp (1-16 shots) ä¸Šè¿›è¡Œäº†å®éªŒã€‚ æ³¨æ„ï¼šç”±äº Windows CPU ç¯å¢ƒçš„é™åˆ¶ï¼Œæˆ‘ä»¬å°† NUM_WORKERS è®¾ä¸º 0 å¹¶è°ƒæ•´äº† BATCH_SIZEã€‚

###  4.1 Zero-shot CLIP (åŸºå‡†)
è¿è¡Œä»¥ä¸‹å‘½ä»¤ä»¥è·å–æœªå¾®è°ƒçš„åŸºå‡†æ€§èƒ½ï¼š

```Bash

python train.py --root ./data --seed 1 --trainer ZeroshotCLIP --dataset-config-file configs/datasets/imagenet.yaml --config-file configs/trainers/CoOp/rn50.yaml --output-dir output/imagenet/ZeroshotCLIP --eval-only DATASET.NUM_SHOTS 0 DATASET.SUBSAMPLE_CLASSES all DATALOADER.NUM_WORKERS 0 DATALOADER.TEST.BATCH_SIZE 32
```

### 4.2 æ ‡å‡† CoOp (Context Length = 16)
ç¤ºä¾‹ï¼š16-shot è®­ç»ƒ
```Bash

python train.py --root ./data --seed 1 --trainer CoOp --dataset-config-file configs/datasets/imagenet.yaml --config-file configs/trainers/CoOp/rn50.yaml --output-dir output/imagenet/CoOp/rn50_16shots DATASET.NUM_SHOTS 16 DATASET.SUBSAMPLE_CLASSES all DATALOADER.NUM_WORKERS 0 DATALOADER.TEST.BATCH_SIZE 32
```
(é€šè¿‡ä¿®æ”¹ DATASET.NUM_SHOTS å’Œè¾“å‡ºç›®å½•åï¼Œé‡å¤è¿è¡Œ 1, 2, 4, 8 shot)

### 4.3 é«˜æ•ˆ CoOp (Context Length = 4) - åˆ›æ–°ç‚¹
ç¤ºä¾‹ï¼š4-shot è®­ç»ƒ (å‚æ•°æ›´å°‘)
```Bash
python train.py --root ./data --seed 1 --trainer CoOp --dataset-config-file configs/datasets/imagenet.yaml --config-file configs/trainers/CoOp/rn50.yaml --output-dir output/imagenet/CoOp/rn50_4shots_ctx4 DATASET.NUM_SHOTS 4 DATASET.SUBSAMPLE_CLASSES all DATALOADER.NUM_WORKERS 0 DATALOADER.TEST.BATCH_SIZE 32 TRAINER.COOP.N_CTX 4
```
(é€šè¿‡ä¿®æ”¹ DATASET.NUM_SHOTS å’Œè¾“å‡ºç›®å½•åï¼Œé‡å¤è¿è¡Œ 1, 2, 8, 16 shot)

## ğŸ“Š 5. ç»“æœä¸åˆ†æ (Results & Analysis)

### 5.1 æ ¸å¿ƒæ€§èƒ½è¡¨ (Accuracy %)

| æ–¹æ³• (Method) | 0-shot | 1-shot | 2-shot | 4-shot | 8-shot | 16-shot |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: |
| **Zero-shot CLIP** | [TODO:å¡«ç»“æœ]% | - | - | - | - | - |
| **CoOp (Standard)**| - | [TODO:å¡«]% | [TODO:å¡«]% | [TODO:å¡«]% | [TODO:å¡«]% | [TODO:å¡«]% |
| **CoOp (Efficient)**| - | [TODO:å¡«]% | [TODO:å¡«]% | [TODO:å¡«]% | [TODO:å¡«]% | [TODO:å¡«]% |

### 5.2 å®éªŒåˆ†æ
1.  **å°‘æ ·æœ¬å­¦ä¹ çš„æœ‰æ•ˆæ€§ï¼š**
    å¦‚è¡¨æ‰€ç¤ºï¼ŒCoOp çš„æ€§èƒ½æ˜¾è‘—ä¼˜äº Zero-shot åŸºå‡†ã€‚å³ä½¿ä»…æœ‰ **1 shot**ï¼Œé€šè¿‡å­¦ä¹ å¾—åˆ°çš„ Prompt ä¹Ÿæ¯”å›ºå®šçš„äººå·¥ Prompt æ›´é€‚åº”å½“å‰æ•°æ®åˆ†å¸ƒã€‚éšç€æ ·æœ¬æ•° (Shots) çš„å¢åŠ ï¼Œå‡†ç¡®ç‡ç¨³æ­¥æå‡ã€‚

2.  **å‚æ•°æ•ˆç‡åˆ†æ (åˆ›æ–°ç‚¹è®¨è®º)ï¼š**
    æˆ‘ä»¬å¯¹æ¯”äº†æ ‡å‡†è®¾ç½® (`N_CTX=16`) å’Œä¼˜åŒ–è®¾ç½® (`N_CTX=4`)ã€‚
    * **å‚æ•°ç¼©å‡:** å°† `N_CTX` è®¾ä¸º 4ï¼Œä½¿å¾—å¯å­¦ä¹ å‚æ•°çš„æ•°é‡å‡å°‘äº† **75%**ã€‚
    * **æ€§èƒ½è¡¨ç°:** å®éªŒç»“æœè¡¨æ˜ï¼Œé«˜æ•ˆç‰ˆ CoOp å–å¾—äº† [TODO: å¡«å†™ "ä¸æ ‡å‡†ç‰ˆç›¸å½“" æˆ– "ç•¥ä½/ç•¥é«˜"] çš„æ€§èƒ½ã€‚
    * **ç»“è®º:** è¿™è¯æ˜äº† CLIP çš„æç¤ºå¾®è°ƒå…·æœ‰å¾ˆå¼ºçš„é²æ£’æ€§ã€‚æˆ‘ä»¬æˆåŠŸåœ°ç”¨**æå°‘çš„å‚æ•°**å¢å¼ºäº†æ¨¡å‹èƒ½åŠ›ï¼Œå®Œç¾å¥‘åˆäº†ä½œä¸šå¯¹äºå‚æ•°æ•ˆç‡çš„è¦æ±‚ã€‚

### 5.3 å®éªŒè¾“å‡ºç›®å½•ç»“æ„è¯´æ˜ (Output Directory Structure)

æ ¹æ®å®éªŒè®¾è®¡ï¼Œè¾“å‡ºæ–‡ä»¶å¤¹å¯¹åº”äº†ä¸‰ç»„ä¸åŒçš„å®éªŒé…ç½®ã€‚è¯·å‚è€ƒä¸‹å›¾ç†è§£æ¯ä¸ªæ–‡ä»¶å¤¹çš„å«ä¹‰ï¼š

```text
output/
â””â”€â”€ imagenet/
    â”œâ”€â”€ CoOp/
    â”‚   â”œâ”€â”€ rn50_1shots/       <-- [1] æ ‡å‡†ç»„ (Standard)
    â”‚   â”œâ”€â”€ rn50_1shots_ctx4/  <-- [2] é«˜æ•ˆç»„ (Efficient/Novelty)
    â”‚   â”œâ”€â”€ ...
    â”‚   â”œâ”€â”€ rn50_16shots/
    â”‚   â””â”€â”€ rn50_16shots_ctx4/
    â””â”€â”€ ZeroshotCLIP/          <-- [3] é›¶æ ·æœ¬åŸºçº¿ (Baseline)
```
![img.png](img.png)

* ç¬¬ä¸€ç»„ï¼šæ ‡å‡† CoOp å®éªŒ (Standard Baseline)
    * æ–‡ä»¶å¤¹ç‰¹å¾: åç§°ä¸­ä¸åŒ…å« _ctx4 åç¼€ï¼ˆä¾‹å¦‚ rn50_16shotsï¼‰ã€‚

    * å®éªŒå«ä¹‰: ä½¿ç”¨ CoOp çš„é»˜è®¤é…ç½®ï¼Œä¸Šä¸‹æ–‡é•¿åº¦ (Context Length) ä¸º 16ã€‚

    * æŠ¥å‘Šç”¨é€”: ä½œä¸ºè¯¥æ–¹æ³•çš„æ ‡å‡†æ€§èƒ½å‚è€ƒï¼Œå¡«å…¥è¡¨æ ¼çš„ "CoOp (Standard)" ä¸€æ ã€‚

* ç¬¬äºŒç»„ï¼šé«˜æ•ˆ CoOp å®éªŒ (Efficient/Novelty)
    * æ–‡ä»¶å¤¹ç‰¹å¾: é«˜æ•ˆ CoOp å®éªŒ (Efficient/Novelty)

    * å®éªŒå«ä¹‰: ä¸ºäº†æ»¡è¶³ä½œä¸šä¸­ "as few parameters as possible" çš„è¦æ±‚ï¼Œæˆ‘ä»¬å°†ä¸Šä¸‹æ–‡é•¿åº¦ (Context Length) å‡å°‘ä¸º 4ã€‚

    * æŠ¥å‘Šç”¨é€”: è¯æ˜æ¨¡å‹åœ¨å‚æ•°é‡å‡å°‘ 75% çš„æƒ…å†µä¸‹ä»èƒ½ä¿æŒæ€§èƒ½ï¼Œå¡«å…¥è¡¨æ ¼çš„ "CoOp (Efficient)" ä¸€æ ã€‚

* ç¬¬ä¸‰ç»„ï¼šé›¶æ ·æœ¬åŸºçº¿ (Zero-shot Baseline)
    * æ–‡ä»¶å¤¹ç‰¹å¾: ZeroshotCLIP

    * å®éªŒå«ä¹‰: æœªç»ä»»ä½•å¾®è°ƒçš„åŸå§‹ CLIP æ¨¡å‹ã€‚

    * æŠ¥å‘Šç”¨é€”: ä½œä¸ºæ€§èƒ½çš„æœ€ä½åŸºå‡†çº¿ï¼ˆBase Performanceï¼‰ï¼Œå¡«å…¥è¡¨æ ¼çš„ "Zero-shot CLIP" ä¸€æ ã€‚

### 5.4 æ•°æ®å¡«è¡¨æŒ‡å— (Data Extraction Guide)

è¯·æ‰“å¼€æ¯ä¸ªæ–‡ä»¶å¤¹ä¸‹çš„ `log.txt` æ–‡ä»¶ï¼Œæå–æœ€åä¸€è¡Œçš„ **Accuracy** æ•°å€¼ï¼Œå¹¶å¯¹åº”å¡«å…¥ä¸‹è¡¨ï¼š

| å®éªŒç±»å‹ | 1-shot æ•°æ®æ¥æº | ... | 16-shot æ•°æ®æ¥æº |
| :--- | :--- | :--- | :--- |
| **Zero-shot** | `ZeroshotCLIP/log.txt` | - | - |
| **Standard** | `rn50_1shots/log.txt` | ... | `rn50_16shots/log.txt` |
| **Efficient** | `rn50_1shots_ctx4/log.txt` | ... | `rn50_16shots_ctx4/log.txt` |


---

## ğŸ“ 6. å‚è€ƒèµ„æ–™ (References)
1.  **OpenAI CLIP:** Radford et al., *Learning Transferable Visual Models From Natural Language Supervision*, ICML 2021.
2.  **CoOp:** Zhou et al., *Learning to Prompt for Vision-Language Models*, IJCV 2022.
3.  **Codebase:** [https://github.com/KaiyangZhou/CoOp](https://github.com/KaiyangZhou/CoOp)




